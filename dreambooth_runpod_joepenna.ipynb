{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b971cc0",
   "metadata": {
    "id": "7b971cc0"
   },
   "source": [
    "## Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37455cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"man\"\n",
    "if dataset == \"man\":\n",
    "    dataset=\"man_euler\"\n",
    "    class_word = \"man\"\n",
    "elif dataset == \"woman\":\n",
    "    dataset=\"woman_ddim\"\n",
    "    class_word = \"woman\"\n",
    "elif dataset == \"person\":\n",
    "    dataset=\"person_ddim\"\n",
    "    class_word = \"person\"\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset.\")\n",
    "    \n",
    "project_name = \"project_name\"\n",
    "\n",
    "max_training_steps = 1000\n",
    "hf_token =\"HUGGINGFACE TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
   "metadata": {
    "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#BUILD ENV\n",
    "!pip install omegaconf\n",
    "!pip install einops\n",
    "!pip install pytorch-lightning==1.6.5\n",
    "!pip install test-tube\n",
    "!pip install transformers\n",
    "!pip install kornia\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install setuptools==59.5.0\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install -e .\n",
    "!pip install protobuf==3.20.1\n",
    "!pip install gdown\n",
    "!pip install pydrive\n",
    "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip install -qq \"ipywidgets>=7,<8\"\n",
    "!pip install huggingface_hub\n",
    "!pip install ipywidgets==7.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae11c10",
   "metadata": {
    "id": "dae11c10"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0420469a0fc46b18dd13c0a6abe6e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub.hf_api import HfFolder\n",
    "\n",
    "HfFolder.save_token(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51418621",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the 1.4 sd model\n",
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"CompVis/stable-diffusion-v-1-4-original\",\n",
    " filename=\"sd-v1-4.ckpt\",\n",
    " use_auth_token=True\n",
    ")\n",
    "\n",
    "## Move the sd-v1-4.ckpt to the root of this directory as \"model.ckpt\"\n",
    "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
    "!mv {actual_locations_of_model_blob[-1]} model.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mxPL2O0OLvBW",
   "metadata": {
    "id": "mxPL2O0OLvBW"
   },
   "source": [
    "## Download pre-generated regularization images\n",
    "\n",
    "We've created the following image sets\n",
    "\n",
    "* man_euler - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
    "* man_unsplash - pictures from various photographers\n",
    "* person_ddim\n",
    "* woman_ddim - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0\n",
    "\n",
    "`person_ddim` is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7EydXCjOV1v",
   "metadata": {
    "id": "e7EydXCjOV1v"
   },
   "outputs": [],
   "source": [
    "# Grab the existing regularization images\n",
    "# Choose the dataset that best represents what you are trying to do and matches what you used for your token\n",
    "# man_euler, man_unsplash, person_ddim, woman_ddim\n",
    "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
    "\n",
    "!mkdir training_samples\n",
    "!mkdir -p outputs/txt2img-samples/samples/{dataset}\n",
    "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* outputs/txt2img-samples/samples/{dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zshrC_JuMXmM",
   "metadata": {
    "id": "zshrC_JuMXmM"
   },
   "source": [
    "# Upload your training images\n",
    "Upload 10-20 images of someone to\n",
    "\n",
    "```\n",
    "/workspace/Dreambooth-Stable-Diffusion/training_samples\n",
    "```\n",
    "\n",
    "WARNING: Be sure to upload an *even* amount of images, otherwise the training inexplicably stops at 1500 steps.\n",
    "\n",
    "*   2-3 full body\n",
    "*   3-5 upper body \n",
    "*   5-12 close-up on face\n",
    "\n",
    "The images should be:\n",
    "\n",
    "- as close as possible to the kind of images you're trying to make (most of the time, that means no selfies).\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b14b3",
   "metadata": {},
   "source": [
    "## Edit the personalized.py file\n",
    "Execute this cell `%load ldm/data/personalized.py`\n",
    "\n",
    "Change `joepenna` to whatever you want it to be (but keep the {})\n",
    "\n",
    "```\n",
    "training_templates_smallest = [\n",
    "    'joepenna {}',\n",
    "]\n",
    "```\n",
    "\n",
    "I recommend using the name of a celebrity that:\n",
    "1) kinda looks like you.\n",
    "2) Stable Diffusion generates well (you can check by typing their name on DreamStudio)\n",
    "\n",
    "Then paste this at the very top of the cell:\n",
    "```\n",
    "%%writefile ldm/data/personalized.py\n",
    "```\n",
    "\n",
    "Then run the cell again.  This will save your changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load ldm/data/personalized.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
   "metadata": {
    "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_data_root = \"/workspace/Dreambooth-Stable-Diffusion/outputs/txt2img-samples/samples/\" + dataset\n",
    "\n",
    "!rm -rf training_samples/.ipynb_checkpoints\n",
    "!python \"main.py\" \\\n",
    " --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
    " -t \\\n",
    " --actual_resume \"model.ckpt\" \\\n",
    " --reg_data_root {reg_data_root} \\\n",
    " -n {project_name} \\\n",
    " --gpus 0, \\\n",
    " --data_root \"/workspace/Dreambooth-Stable-Diffusion/training_samples\" \\\n",
    " --max_training_steps {max_training_steps} \\\n",
    " --class_word {class_word} \\\n",
    " --no-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49d0bd",
   "metadata": {},
   "source": [
    "## Pruning (12GB to 2GB)\n",
    "We are working on having this happen automatically (TODO: PR's welcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_paths = !ls -d logs/*\n",
    "\n",
    "# This version should automatically prune around 10GB from the ckpt file\n",
    "last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
    "!python \"prune_ckpt.py\" --ckpt {last_checkpoint_file}\n",
    "\n",
    "last_checkpoint_file_pruned = directory_paths[-1] + \"/checkpoints/last-pruned.ckpt\"\n",
    "training_samples = !ls training_samples\n",
    "date_string = !date +\"%Y-%m-%dT%H-%M-%S\"\n",
    "file_name = date_string[-1] + \"_\" + project_name + \"_\" + str(len(training_samples)) + \"_training_images_\" +  str(max_training_steps) + \"_max_training_steps_\" + class_word + \"_class_word.ckpt\"\n",
    "!mkdir -p trained_models\n",
    "!mv {last_checkpoint_file_pruned} trained_models/{file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download your trained model file from `trained_models` and use in your favorite Stable Diffusion repo!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90ac5c",
   "metadata": {},
   "source": [
    "# Big Important Note!\n",
    "\n",
    "The way to use your token is `<token> <class>` ie `joepenna person` and not just `joepenna`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d0139",
   "metadata": {},
   "source": [
    "## Generate Images With Your Trained Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ddb03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File \"scripts/stable_txt2img.py\", line 26\r\n",
      "    print(f\"Loading model from {ckpt}\")\r\n",
      "                                     ^\r\n",
      "SyntaxError: invalid syntax\r\n"
     ]
    }
   ],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 1 \\\n",
    " --n_iter 4 \\\n",
    " --scale 7.0 \\\n",
    " --ddim_steps 50 \\\n",
    " --ckpt \"/workspace/Dreambooth-Stable-Diffusion/trained_models/{file_name}\" \\\n",
    " --prompt \"joepenna {class_word}, painting by greg rutkowski and alphonse mucha, masterpiece, trending on artstation\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
